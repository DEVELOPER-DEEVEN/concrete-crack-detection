# ğŸ“Œ Concrete Crack Detection using Convolutional Neural Networks

<p align="center">
  <img src="assets/image_concrete.jpg" alt="image_concrete" width="500"/>
</p>

## ğŸ“– Description
This project is a machine learning model designed to train a convolutional neural network to classify concrete images, wether a crack is present or not. The model is trained on the Mendeley Data [2] dataset to achieve high accuracy in distinguishing between fractured and non-fractured concrete stuctures.

<p align="center">
  <img src="assets/objective.jpg" alt="objective" width="500"/>
</p>

## ğŸ“ Project Structure

```txt
/concrete-crack-detection
â”‚â”€â”€ README.md               # Project overview and instructions
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ notebooks/              # Jupyter notebooks for EDA and model training
â”‚â”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/               # Data processing scripts
â”‚   â”œâ”€â”€ models/             # Model definition, training, and evaluation
â”‚   â”œâ”€â”€ utils/              # Helper functions
â”‚â”€â”€ data/                   # Raw and processed datasets (ignored in Git)
â”‚   â”œâ”€â”€ raw/                # Data processing scripts
â”‚   â”œâ”€â”€ processed/          # Feature X and target y
â”‚â”€â”€ models/                 # Saved model files
```

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/DEVELOPER-DEEVEN/concrete-crack-detection.git
cd concrete-crack-detection
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # For Mac/Linux
venv\Scripts\activate  # For Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

## ğŸ–¥ Usage

This repository comes already with the loaded that
1. Download the dataset:
To donwload the data, it is provided by [1] (refference): https://data.mendeley.com/datasets/5y9wdsg2zt/2

  - Run the file located in `src\data\data_loader.py` and specify the amount of images to be donwloaded for each class. With:

  ```bash
  python -m src\data\data_loader.py
  ```

  - Run the `processing_loader.py` to perform image processing on the original images (grayscale, filtering, sobol).


2. run the `src\main.ipynb` to train the model and then saving it.

## ğŸ“Œ Dataset

<p align="center">
  <img src="assets/example_dataset.jpg" alt="example_dataset" width="500"/>
</p>


<p align="center">
  <img src="assets/dataset.jpg" alt="dataset.jpg" width="300"/>
</p>


Source: [[Dataset Name & Link]](https://data.mendeley.com/datasets/5y9wdsg2zt/2)

Preprocessing example:

<p align="center">
  <img src="assets/image_preprocessing_neg.jpg" alt="image_preprocessing_neg" width="700"/>
</p>

<p align="center">
  <img src="assets/image_preprocessing_pos.jpg" alt="image_preprocessing_pos" width="700"/>
</p>


## ğŸ“Š Results

<p align="center">
  <img src="assets/results.png" alt="objective" width="800"/>
</p>


